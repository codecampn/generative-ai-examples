{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUAyvUqhN3sP"
      },
      "source": [
        "# LLM Example: Detect Throwaway mail domains\n",
        "\n",
        "Find out whether a mail domain is from a one-time mail provider. These providers are often operating under different names and creating and updating a blacklist is tedious. This example uses a llm agent to search with duckduckgo for the mail provider and give a statement wheter a domain is a throwaway address.\n",
        "\n",
        "> Looking for someone to kickstart your Generative AI project? \\\n",
        "  Write me a message (jannis.gansen@codecamp-n.com) and check out https://www.codecamp-n.com/  \\\n",
        "  ![CodeCampN.png](../logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuixLzNHPd4i"
      },
      "source": [
        "## 1. ‚õìÔ∏è Install dependencies\n",
        "\n",
        "- We'll use langchain for creating our agent\n",
        "- openai for accessing the OpenAI models\n",
        "- duckduckgo-search for querying the mail provider (as this doesn't require an account or key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERGZ0MwdMcQZ",
        "outputId": "e25765a1-8675-4783-e34e-85b3e23f82a5"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai duckduckgo-search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAyfT2aGRYYq"
      },
      "source": [
        "## 2. üîë Setup credentials\n",
        "\n",
        "You have two options to set your credentials:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ9MBHBlSMNO"
      },
      "source": [
        "\n",
        "### Option 1: Set environment directly in the notebook\n",
        "\n",
        "Insert your OpenAPI Key into the OPENAI_API_KEY environment variable, but make sure to not share this information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6D6L-wcR8z3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"** Your Key **\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkZRg7qZSPs7"
      },
      "source": [
        "### Option 2: Query via getpass\n",
        "\n",
        "This requries the user of the notebook to provide the key.\n",
        "\n",
        "Pro: You can't lose your key \\\n",
        "Con: You need to enter it everytime you restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GWCx2YHSloU",
        "outputId": "2de159b2-4ecd-4684-c029-e51c35b59008"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass('Your OPENAI key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38A65R_-TMBf"
      },
      "source": [
        "## 3. üõ†Ô∏è Setup your agent\n",
        "\n",
        "For this example we'll use a GPT-3.5-turbo chatmodel and a Search Engine tool.\n",
        "Langchain provides tools for this.\n",
        "\n",
        "We'll use\n",
        "- the ChatOpenAI model from langchain to access OpenAI Models with our agent\n",
        "- the DuckDuckGoSearchRun tool from langchain to provide a tool for looking up domains\n",
        "\n",
        "The following block is setting up the tools. Notice how we tell our model *what* it can actually do with each tool.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "zLSN5vA9QyYm"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain.agents import Tool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"\"\"\n",
        "Useful for when you need to answer questions about a domain. You can search for the domain name and 'no account required'\n",
        "\"\"\"\n",
        "    )\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67BX9kzZdImA"
      },
      "source": [
        "Next we create an agent that will perform a task for us.\n",
        "Providing the tools allow our the agent to search for entries.\n",
        "\n",
        "We'll use OPENAI_FUNCTIONS as the agent type, as the model is trained for working with tools. Check out the [Agent Types](https://python.langchain.com/docs/modules/agents/agent_types/) in the langchain documentation and feel free to try others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Zge451THarbr"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eadGmBMleina"
      },
      "source": [
        "## 4. üïµÔ∏è‚Äç‚ôÄÔ∏è Run your agent\n",
        "\n",
        "Executing your agent is simple now, we first create a prompt template (beware that this is isn't preventing prompt injection!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "8Wn64Osued6x"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "\n",
        "template = \"\"\"\\\n",
        "You are responsible for finding out whether an users domain is allowed to \\\n",
        "  access your service.\n",
        "\n",
        "Only domains that are not from one-time, temporary, disposable or throw away mail providers are allowd\n",
        "Is the domain from the mail {mail} allowed?\n",
        "\n",
        "Explicitly search wether you can send mails without an account from this service.\n",
        "If it is not explicitly promoted as disposable, anonymous, etc. the service should be allowed.\n",
        "\n",
        "Return the answer as a json with the boolean field \"allowed\".\n",
        "Only return JSON.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwpjHPCpgTm1"
      },
      "source": [
        "...and finally we can execute the agent using the prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpkidking8hh"
      },
      "source": [
        "This should not be allowed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "tlOUo4Wgfa0O",
        "outputId": "ddff9914-69ed-43f5-92c4-364742d98d1c"
      },
      "outputs": [],
      "source": [
        "agent.run(prompt.format(mail=\"throwawaymail.com\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aetBOzQ6iLs0"
      },
      "source": [
        "...while this should be a reputable source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "jgLC35tqgm-W",
        "outputId": "6ef53be7-228a-47d6-c96b-39dfa5ff594e"
      },
      "outputs": [],
      "source": [
        "agent.run(prompt.format(mail=\"gmail.com\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHjZJxLfmCtL"
      },
      "source": [
        "## üöÄ Where do we go from here?\n",
        "\n",
        "### Improve the prompt\n",
        "\n",
        "You may notice that the response isn't always json.\n",
        "Can you figure out how to fix it?\n",
        "Ideas:\n",
        "- Tune the prompt\n",
        "- Createa a second call to the LLM that converts the response to a json.\n",
        "\n",
        "Also check out the [Output parsers](https://python.langchain.com/docs/modules/model_io/output_parsers/) from langchain!\n",
        "\n",
        "### Contact us!\n",
        "\n",
        "Check out codecamp-n.com and feel free to drop me a message via\n",
        " \n",
        "- ‚úâÔ∏è Mail: jannis.gansen@codecamp-n.com\n",
        "- or LinkedIn https://www.linkedin.com/in/jannis-gansen/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
