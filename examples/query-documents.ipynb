{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsZDZTEqek_x"
      },
      "source": [
        "# LLM Example: Summarize PDF Contents\n",
        "\n",
        "Take a PDF and summarize it's content according for the given target group\n",
        "\n",
        "> Looking for someone to kickstart your Generative AI project? \\\n",
        "  Write me a message (jannis.gansen@codecamp-n.com) and check out https://www.codecamp-n.com/  \\\n",
        "  ![CodeCampN.png](../logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykQZQnrwfEGL"
      },
      "source": [
        "## 1. â›“ï¸ Install dependencies\n",
        "\n",
        "- We'll use langchain for creating our agent\n",
        "- openai for accessing the OpenAI models\n",
        "- pypdf for parsing PDF files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZJ6XbSjejIg"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai pypdf tiktoken chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80ynITmEfqDs"
      },
      "source": [
        "## 2. ðŸ”‘ Setup credentials\n",
        "\n",
        "You have two options to set your credentials:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUTwW_1ygDM0"
      },
      "source": [
        "\n",
        "### Option 1: Set environment directly in the notebook\n",
        "\n",
        "Insert your OpenAPI Key into the OPENAI_API_KEY environment variable, but make sure to not share this information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "T2oNqlwJgHx_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"** Your Key **\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ9dI9cGgLMO"
      },
      "source": [
        "### Option 2: Query via getpass\n",
        "\n",
        "This requries the user of the notebook to provide the key.\n",
        "\n",
        "Pro: You can't lose your key \\\n",
        "Con: You need to enter it everytime you restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7btOPLLgOwn",
        "outputId": "8101544d-093f-451d-8b59-66d9c8ed451a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your OPENAI key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass('Your OPENAI key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjtk8BYQhSJi"
      },
      "source": [
        "## 3. Load and preprocess PDF\n",
        "Langchain provides a PyPDFLoader implementation that simplifies\n",
        "loading and splittng PDF documents by pages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Download a doument\n",
        "\n",
        "First lets download the german \"Umsatzsteuergesetz\" and use this as our knowledge source."
      ],
      "metadata": {
        "id": "0gQ4nWpqmtni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib import request\n",
        "\n",
        "remote_url = 'https://www.gesetze-im-internet.de/ustg_1980/UStG.pdf'\n",
        "\n",
        "local_file = 'ustg_2023.pdf'\n",
        "request.urlretrieve(remote_url, local_file)\n",
        "doc_name = local_file"
      ],
      "metadata": {
        "id": "et9gIl98mBtS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        ">  (Optional) If you want to try with your own document you can upload it here in a colab environment:"
      ],
      "metadata": {
        "id": "R8lFgv1hkSI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "doc_name = uploaded.keys()[0]"
      ],
      "metadata": {
        "id": "kvpZLhg4jJ4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Create embeddings and store them in a vector database\n",
        "\n",
        "We'll use chroma as a vector database and store the pdf. For this we'll split the document first using langchains [RecursiveTextSplitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter), as this tries to keep paragraphs together."
      ],
      "metadata": {
        "id": "qWmRJiZBnZyb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0_8dusQhuh_",
        "outputId": "89602045-b8d9-4aec-dd03-c7ee334539ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = PyPDFLoader(doc_name)\n",
        "pages = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "\n",
        "    chunk_size = 4096,\n",
        "    chunk_overlap  = 128,\n",
        "    length_function = len,\n",
        "    is_separator_regex = False,\n",
        ")\n",
        "docs = text_splitter.split_documents(pages)\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll create embeddings for the document and add them to our vector store:"
      ],
      "metadata": {
        "id": "vn_rPOxUp8b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "db = Chroma.from_documents(docs, embeddings, persist_directory=\"./chroma_db_ustg\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N5iqr9CqqCMz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test whether we find information in our vector store. We'll use a max marginal relevance search, as this produces good results in our demo case."
      ],
      "metadata": {
        "id": "L14DbRI6abnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Kleinunternehmer\"\n",
        "found_docs = db.max_marginal_relevance_search(query, k=2, fetch_k=10)\n",
        "\n",
        "found_docs"
      ],
      "metadata": {
        "id": "ulj7fY9Faf7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMElnrKmhJvu"
      },
      "source": [
        "## 4. â›“ï¸ Use the vector store as a retriever\n",
        "\n",
        "We have everything in place to build our agent now. Our Agent will get the document search as a retriever and use a ZERO SHOT REACT DESCRIPTION type. Feel free to experiment with different settings!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_NE27ja2tHKH"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# or use gpt-4 if it's available in your account, as it performs better\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
        "\n",
        "ustgSearch = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=db.as_retriever(search_type=\"mmr\")\n",
        ")\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"UstG Suche\",\n",
        "        func=ustgSearch.run,\n",
        "        description=\"NÃ¼tzlich wenn du fragen zu gesetzliche Rahmenbedingungen aus dem UstG hast (Umsatzsteuergesetz)\",\n",
        "    ),\n",
        "]\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title UstG Prompt\n",
        "# @markdown ...and finally you can test your prompt!\n",
        "prompt = \"Wann ist man Kleinunternehmer laut UstG? \" # @param {type:\"string\"}\n",
        "\n",
        "agent.run(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "AWnOiF5wjsXE",
        "outputId": "7b01ee84-bd5c-4daf-b4e7-e4d319977487"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mUm diese Frage zu beantworten, muss ich das Umsatzsteuergesetz (UstG) konsultieren, um die genauen Bedingungen fÃ¼r die Einstufung als Kleinunternehmer zu finden.\n",
            "Action: UstG Suche\n",
            "Action Input: Kleinunternehmer\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mKleinunternehmer sind Unternehmer, die im Inland oder in den in Â§ 1 Abs. 3 bezeichneten Gebieten ansÃ¤ssig sind und deren Umsatz im vorangegangenen Kalenderjahr 22.000 Euro nicht Ã¼berstiegen hat und im laufenden Kalenderjahr 50.000 Euro voraussichtlich nicht Ã¼bersteigen wird. FÃ¼r diese Unternehmer wird die Umsatzsteuer fÃ¼r UmsÃ¤tze im Sinne des Â§ 1 Abs. 1 Nr. 1 nicht erhoben.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mIch habe jetzt die Informationen, um die Frage zu beantworten.\n",
            "Final Answer: Laut Umsatzsteuergesetz (UstG) ist man ein Kleinunternehmer, wenn man im Inland oder in den in Â§ 1 Abs. 3 bezeichneten Gebieten ansÃ¤ssig ist und der Umsatz im vorangegangenen Kalenderjahr 22.000 Euro nicht Ã¼berstiegen hat und im laufenden Kalenderjahr 50.000 Euro voraussichtlich nicht Ã¼bersteigen wird. FÃ¼r diese Unternehmer wird die Umsatzsteuer fÃ¼r UmsÃ¤tze im Sinne des Â§ 1 Abs. 1 Nr. 1 nicht erhoben.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Laut Umsatzsteuergesetz (UstG) ist man ein Kleinunternehmer, wenn man im Inland oder in den in Â§ 1 Abs. 3 bezeichneten Gebieten ansÃ¤ssig ist und der Umsatz im vorangegangenen Kalenderjahr 22.000 Euro nicht Ã¼berstiegen hat und im laufenden Kalenderjahr 50.000 Euro voraussichtlich nicht Ã¼bersteigen wird. FÃ¼r diese Unternehmer wird die Umsatzsteuer fÃ¼r UmsÃ¤tze im Sinne des Â§ 1 Abs. 1 Nr. 1 nicht erhoben.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸš€ Where do we go from here?\n",
        "\n",
        "### Improve the prompt\n",
        "\n",
        "You can try to embed relevant inforamtion directly using a Prompt Template\n"
      ],
      "metadata": {
        "id": "2lHJYAYkdB5F"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "R8lFgv1hkSI0"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}