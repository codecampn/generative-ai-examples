{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsZDZTEqek_x"
      },
      "source": [
        "# LLM Example: Query documents \n",
        "\n",
        "This example takes a (german) law description and allows you to query it.\n",
        "\n",
        "> Looking for someone to kickstart your Generative AI project? \\\n",
        "  Write me a message (jannis.gansen@codecamp-n.com) and check out https://www.codecamp-n.com/  \\\n",
        "  ![CodeCampN.png](../logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykQZQnrwfEGL"
      },
      "source": [
        "## 1. ⛓️ Install dependencies\n",
        "\n",
        "- We'll use langchain for creating our agent\n",
        "- openai for accessing the OpenAI models\n",
        "- pypdf for parsing PDF files\n",
        "- tiktoken as we need to create embeddings\n",
        "- chromadb for creating a local vector store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZJ6XbSjejIg"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai pypdf tiktoken chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80ynITmEfqDs"
      },
      "source": [
        "## 2. 🔑 Setup credentials\n",
        "\n",
        "You have two options to set your credentials:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUTwW_1ygDM0"
      },
      "source": [
        "\n",
        "### Option 1: Set environment directly in the notebook\n",
        "\n",
        "Insert your OpenAPI Key into the OPENAI_API_KEY environment variable, but make sure to not share this information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "T2oNqlwJgHx_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"** Your Key **\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ9dI9cGgLMO"
      },
      "source": [
        "### Option 2: Query via getpass\n",
        "\n",
        "This requries the user of the notebook to provide the key.\n",
        "\n",
        "Pro: You can't lose your key \\\n",
        "Con: You need to enter it everytime you restart the kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7btOPLLgOwn",
        "outputId": "8101544d-093f-451d-8b59-66d9c8ed451a"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass('Your OPENAI key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjtk8BYQhSJi"
      },
      "source": [
        "## 3. Load and preprocess PDF\n",
        "Langchain provides a PyPDFLoader implementation that simplifies\n",
        "loading and splittng PDF documents by pages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gQ4nWpqmtni"
      },
      "source": [
        "### 3.1 Download a doument\n",
        "\n",
        "First lets download the german \"Umsatzsteuergesetz\" and use this as our knowledge source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "et9gIl98mBtS"
      },
      "outputs": [],
      "source": [
        "from urllib import request\n",
        "\n",
        "remote_url = 'https://www.gesetze-im-internet.de/ustg_1980/UStG.pdf'\n",
        "\n",
        "local_file = 'ustg_2023.pdf'\n",
        "request.urlretrieve(remote_url, local_file)\n",
        "doc_name = local_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8lFgv1hkSI0"
      },
      "source": [
        "\n",
        ">  (Optional) If you want to try with your own document you can upload it here in a colab environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvpZLhg4jJ4c"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "doc_name = uploaded.keys()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWmRJiZBnZyb"
      },
      "source": [
        "### 3.2 Create embeddings and store them in a vector database\n",
        "\n",
        "We'll use chroma as a vector database and store the pdf. For this we'll split the document first using langchains [RecursiveTextSplitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter), as this tries to keep paragraphs together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0_8dusQhuh_",
        "outputId": "89602045-b8d9-4aec-dd03-c7ee334539ac"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = PyPDFLoader(doc_name)\n",
        "pages = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "\n",
        "    chunk_size = 4096,\n",
        "    chunk_overlap  = 128,\n",
        "    length_function = len,\n",
        "    is_separator_regex = False,\n",
        ")\n",
        "docs = text_splitter.split_documents(pages)\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn_rPOxUp8b_"
      },
      "source": [
        "Next we'll create embeddings for the document and add them to our vector store:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N5iqr9CqqCMz"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "db = Chroma.from_documents(docs, embeddings, persist_directory=\"./chroma_db_ustg\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L14DbRI6abnN"
      },
      "source": [
        "Let's test whether we find information in our vector store. We'll use a max marginal relevance search, as this produces good results in our demo case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulj7fY9Faf7U"
      },
      "outputs": [],
      "source": [
        "query = \"Kleinunternehmer\"\n",
        "found_docs = db.max_marginal_relevance_search(query, k=2, fetch_k=10)\n",
        "\n",
        "found_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMElnrKmhJvu"
      },
      "source": [
        "## 4. ⛓️ Use the vector store as a retriever\n",
        "\n",
        "We have everything in place to build our agent now. Our Agent will get the document search as a retriever and use a ZERO SHOT REACT DESCRIPTION type. Feel free to experiment with different settings!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_NE27ja2tHKH"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# or use gpt-4 if it's available in your account, as it performs better\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
        "\n",
        "ustgSearch = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=db.as_retriever(search_type=\"mmr\")\n",
        ")\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"UstG Suche\",\n",
        "        func=ustgSearch.run,\n",
        "        description=\"Nützlich wenn du fragen zu gesetzliche Rahmenbedingungen aus dem UstG hast (Umsatzsteuergesetz)\",\n",
        "    ),\n",
        "]\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "AWnOiF5wjsXE",
        "outputId": "7b01ee84-bd5c-4daf-b4e7-e4d319977487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mUm diese Frage zu beantworten, muss ich das Umsatzsteuergesetz (UstG) konsultieren, um die genauen Bedingungen für die Einstufung als Kleinunternehmer zu finden.\n",
            "Action: UstG Suche\n",
            "Action Input: Kleinunternehmer\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mKleinunternehmer sind Unternehmer, die im Inland oder in den in § 1 Abs. 3 bezeichneten Gebieten ansässig sind und deren Umsatz im vorangegangenen Kalenderjahr 22.000 Euro nicht überstiegen hat und im laufenden Kalenderjahr 50.000 Euro voraussichtlich nicht übersteigen wird. Für diese Unternehmer wird die Umsatzsteuer für Umsätze im Sinne des § 1 Abs. 1 Nr. 1 nicht erhoben.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mIch habe jetzt die Informationen, um die Frage zu beantworten.\n",
            "Final Answer: Laut Umsatzsteuergesetz (UstG) ist man ein Kleinunternehmer, wenn man im Inland oder in den in § 1 Abs. 3 bezeichneten Gebieten ansässig ist und der Umsatz im vorangegangenen Kalenderjahr 22.000 Euro nicht überstiegen hat und im laufenden Kalenderjahr 50.000 Euro voraussichtlich nicht übersteigen wird. Für diese Unternehmer wird die Umsatzsteuer für Umsätze im Sinne des § 1 Abs. 1 Nr. 1 nicht erhoben.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Laut Umsatzsteuergesetz (UstG) ist man ein Kleinunternehmer, wenn man im Inland oder in den in § 1 Abs. 3 bezeichneten Gebieten ansässig ist und der Umsatz im vorangegangenen Kalenderjahr 22.000 Euro nicht überstiegen hat und im laufenden Kalenderjahr 50.000 Euro voraussichtlich nicht übersteigen wird. Für diese Unternehmer wird die Umsatzsteuer für Umsätze im Sinne des § 1 Abs. 1 Nr. 1 nicht erhoben.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title UstG Prompt\n",
        "# @markdown ...and finally you can test your prompt!\n",
        "prompt = \"Wann ist man Kleinunternehmer laut UstG? \" # @param {type:\"string\"}\n",
        "\n",
        "agent.run(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lHJYAYkdB5F"
      },
      "source": [
        "## 🚀 Where do we go from here?\n",
        "\n",
        "### Improve the prompt\n",
        "\n",
        "You can try to embed relevant inforamtion directly using a Prompt Template\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "R8lFgv1hkSI0"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
